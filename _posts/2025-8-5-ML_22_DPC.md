---
title: 机器学习（22）密度峰值聚类——Density Peak Clustering. DPC
tags: ML Clustering
typora-root-url: ./..
---

思想：聚类中心点的密度高于其邻近点，且与更高密度的点之间保持相对较远的距离。

<!--more-->

论文：Clustering by fast search and find of density peaks

##### 1.假设

DPC首先有两个假设：

假设1：聚类中心被低局部密度邻居包围，也就是聚类中心点的密度比它的邻居密度要大。

假设2：且与更高密度点保持较大距离，也就是不同聚类中心点尽可能远。

##### 2.定义

（1）每个数据点的局部密度$ \rho_i$，是该数据点与其他数据点的距离$d_{ij}$小于设定的截断距离$d_c$下的数据点总数

$$ \rho_i = \sum_j \chi(d_{ij} - d_c) $$

$$ \chi(x)=\left\{\begin{array}{1}
1,x<0\\
0,otherwise
\end{array}\right. $$

（2）与密度更高的数据点之间距离$ \delta_i $为当前数据点到 “更高密度区域” 的最近距离

$$ \delta_i = \underset{j:\rho_j>\rho_i}{min} d_{ij} $$

注意到密度最大的数据点没有比它密度更高的数据点，也就无法获取$ \delta_i $，故定义密度最高的点的密度$ \delta_i = max_j d_{ij} $。

注：把$ \delta_i $理解为非中心点划分簇的距离依据：距离越小，越可能属于某个簇；距离越大，越不可能属于某个簇。当距离最大时，这个点更可能作为一个新的聚类中心。

##### 3.簇划分

基于第一节的两个假设，局部密度高且离更高密度点距离最大的点，也就是高$\delta$和高$\rho$的点可以作为中心点。而高$\delta$低$\rho$点则为孤立点（异常值）。

![](/assets/images/DPC/one.png)

确定中心点后，每个剩余点被分配到比其密度更高且距离最近的邻居所属簇。为量化分配可靠性，通过定义簇边界区域（与其它簇距离小于$d_c$的点集），确定边界内最高密度$\rho_b$，将密度高于$\rho_b$的点归为中心点（强关联），其余归为光晕点（可视为噪声）。

##### 4.优缺点

优点

- 对数据分布要求不高，尤其对于非球形簇。

- 原理简单，功能强大。

缺点

- 二次时间复杂度，效率低，大数据集不友好。

- 不适合高维。

- 截断距离是一个超参数，需要选择。

~~~
~~~



~~~
~~~

