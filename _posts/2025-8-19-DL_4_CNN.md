---
title: 深度学习（4）初识卷积神经网络CNN
tags: DL CNN CV
typora-root-url: ./..
---

认识卷积神经⽹络（convolutional neural network，CNN）的由来、特点。

<!--more-->

##### 1.CNN的由来

在前面的例子中，我们处理过图像数据，将二维数据展平为一维数据作为输入，通过网络更新参数。但这个过程有一些问题：

（1）将图像展平为一维数据进行训练时，需要处理大量的参数，参数过多会导致模型过拟合，将噪声和特殊情况也学习了；

（2）参数过多还容易导致计算复杂度偏高，GPU消耗非常多，难以求解；

（3）难以有效提取图像中的局部特征。

###### 1.1 图像怎么表示

首先，先了解图像怎么用计算机表达。

对于一个简单的黑白图像，可以用一个二维列表表示，每个元素代表一个0到255区间的像素，0是最暗的（黑），255是最亮的（白）。

~~~
import numpy as np
import matplotlib.pyplot as plt

# 定义图像二维列表
image = np.array([
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,0,0,1,12,0,11,39,137,0,152,147,84,0,0,0,0,0],
    [0,0,1,0,0,41,160,250,255,255,162,255,238,206,11,13,0,0],
    [0,0,16,9,150,251,45,21,184,159,154,255,233,40,0,0,0,0],
    [10,0,0,0,145,146,3,10,0,11,124,253,255,187,0,0,0,0],
    [0,0,3,4,15,236,216,0,38,189,247,240,169,0,11,0,0,0],
    [1,0,2,0,0,253,253,23,62,224,241,255,164,0,5,0,0,0],
    [6,0,4,0,3,252,250,228,255,255,234,112,28,0,2,17,0,0],
    [0,2,1,4,21,255,253,251,255,172,31,8,0,1,0,0,0,0],
    [0,0,4,163,225,255,255,229,120,0,0,0,0,11,0,0,0,0],
    [0,21,162,255,255,255,255,126,0,10,14,6,0,0,9,0,0,0],
    [3,79,242,255,141,66,255,255,189,7,0,0,5,0,0,0,0,0],
    [26,221,237,98,67,251,255,144,0,0,7,0,0,11,0,0,0,0],
    [125,255,141,87,244,255,250,3,0,13,1,0,1,0,0,0,0,0],
    [145,248,228,116,235,255,141,34,0,11,1,0,0,0,1,3,0,0],
    [85,237,253,246,255,210,21,1,0,0,6,2,4,0,0,0,0,0],
    [6,23,112,157,114,32,0,0,0,2,0,8,0,7,0,0,0,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
])

# 绘制黑白图形
plt.imshow(image, cmap='gray', vmin=0, vmax=255)
plt.title('image')
plt.show()
~~~

![](/images/CNN/2.png)

如果是一张彩色图片，即RGB颜色图像，每个位置的像素是由红、绿、蓝三原色组合的列表形成，也就是(红,绿,蓝)，颜色对应位置是0到255的亮度数值。例如，红为(255,0,0)，绿为(0,255,0)，蓝为(0,0,255)，0的位置代表该位置的颜色最暗。而这种颜色列表又被称为**通道**，通道数量代表颜色数量，(255,0,0)用通道解释如下，第一个红色通道取255，第二个绿色通道取0，第三个蓝色通道取0。

一张图片的像素可能是28×28（宽×高），加上颜色，会形成一个三维张量28×28×3。

![](/images/CNN/1.png)

而图像大小，一般指的是像素宽高的多少，像素越高，图像越大，参数越多。一张图像的参数都已经如此庞大了，如果用几百张甚至上千张图片来训练，那么参数高达28×28×3×1000=235.2万！

所以即使GPU计算高效，想要处理图像问题，也是一个巨大的挑战。

###### 1.2 图像的特征

对于一张图像而言，上面通常蕴含丰富的特征，例如一张猫的图象，有猫的颜色、大小、毛发纹理等特征，这些特征由人眼观察很容易区分，可是对于机器而言，这是一个巨大的挑战。

![](/images/CNN/3.png)

在之前处理图像数据时，我们将图像数据展平，变成了一维的数据，于此同时，图像的特征结构也被破坏了。如果我们想要输出猫的位置信息，计算机几乎不可能做到，如果图像上有两只猫，并且他们的姿势不一样，计算机也无法准确识别。

以下图为例，假设pirture红框位置是一只猫，数据展平后，猫的特征被拆开，最后训练出一个可以输出形状特征的函数，但是这个特征只能识别固定位置的猫，对于不同位置的猫却无法识别。也就是说，计算机并不是真正学到了猫的特征，所以没法输出我们想要的结果。

![](/images/CNN/4.png)

###### 1.3 CNN的性质

（1）平移不变形（translation invariance）。正如1.2所说，我们希望猫不管在图像中的哪个位置，都能准确识别，所以神经⽹络的前⾯⼏层应该对相同的图像区域具有相似的反应，即为“平移不变性”。

（2）局部性（locality）。猫的像素位置通常位于某个局部，如果两个像素距离很远，这两个像素属于同一只猫的概率非常低，所以神经⽹络的前⾯⼏层应该只探索输⼊图像中的局部区域，⽽不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。

##### 2.卷积层

在卷积神经网络中，卷积操作是指将一个可移动的小窗口（称为数据窗口）与图像进行逐元素相乘然后相加的操作，这个小窗口是一组固定的权重，用于提取局部的特征。

为了方便理解，这里不再记录数学公式，而是通过图片操作方便理解卷积的运算规则。如果想要知道更多跟数学相关的内容，可以参考邱锡鹏的神经网络。

###### 2.1 卷积运算

卷积操作实际上是实现互相关运算（cross-correlation）。假设输入一张二维3×3图像，使用一个2×2的小窗口，按照从左到右，从上到下滑动，实现相乘、相加操作。

![](/images/CNN/5.png)

$$ 0 \times 0 + 1 \times 1 + 3 \times 2 + 4 \times 3 = 19 $$

$$ 1 \times 0 + 2 \times 1 + 4 \times 2 + 5 \times 3 = 25 $$

$$ 3 \times 0 + 4 \times 1 + 6 \times 2 + 7 \times 3 = 37 $$

$$ 4 \times 0 + 5 \times 1 + 7 \times 2 + 8 \times 3 = 43 $$

这个小窗口通常被称作**卷积核窗口**或**卷积窗口**，更简洁的，可以称为**卷积核**或者**滤波器**。

注意，输出⼤⼩略⼩于输⼊⼤⼩。这是因为卷积核的宽度和⾼度⼤于1，⽽卷积核只与图像中每个⼤⼩完全适合的位置进⾏互相关运算。所以，输出⼤⼩等于输⼊⼤⼩$n_h × n_w$减去卷积核⼤⼩$k_h × k_w$，即：
$$(n_h − k_h + 1) × (n_w − k_w + 1)$$

此外，这个地方展示了卷积神经网络的两个核心特点：**局部连接**和**权值共享**。

- 局部连接：每个神经元只与前一层输入数据中的局部区域连接，而非全连接。
- 权值共享：通过同一个卷积核滑动窗口计算输出，使用相同的权重参数。

###### 2.2 代码实现卷积运算

我们可以自定义一个函数来实现2.1节中的卷积运算。

~~~
import torch
from torch import nn

def corr2d(X, K):
    # 获取K的尺寸：高和宽
    h, w = K.shape
    # 计算输出尺寸
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    # 卷积运算
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y
    
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])
print(corr2d(X, K))
~~~

###### 2.3 定义一个卷积层

卷积层对输⼊和卷积核权重进⾏互相关运算，并在添加标量偏置之后产⽣输出。所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。就像我们之前随机初始化全连接层⼀样，在训练基于卷积层的模型时，我们也随机初始化卷积核权重。

~~~
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))
        
    def forward(self, x):
        return corr2d(x, self.weight) + self.bias

# 设置卷积核尺寸
conv2d = Conv2D((2,2))

# 卷积运算
print(conv2d(X))
~~~

⾼度和宽度分别为h和w的卷积核可以被称为$h × w$卷积或$h × w$卷积核。我们也将带有$h × w$卷积核的卷积层称为$h × w$卷积层。

如果不想自定义卷积层，也可以使用内置的卷积层函数。第一个是输入通道，第二个是输出通道，第三个是卷积核尺寸，第四个是是否添加偏置。

~~~
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)
~~~

###### 2.4 学习卷积核

正如全连接网络的权重参数一样，卷积核的参数也可以学习优化。我们先构造⼀个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们⽐较Y与卷积层输出的平⽅误差，然后计算梯度来更新卷积核。

~~~
X = torch.ones((6, 8))
X[:, 2:6] = 0

# 初始卷积核K
K = torch.tensor([[1.0, -1.0]])
Y = corr2d(X, K)

# 构造⼀个⼆维卷积层，它具有1个输出通道和形状为（1，2）的卷积核
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)

# 这个⼆维卷积层使⽤四维输⼊和输出格式（批量⼤⼩、通道、⾼度、宽度），
# 其中批量⼤⼩和通道数都为1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
lr = 3e-2 # 学习率
for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    # 迭代卷积核
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'epoch {i+1}, loss {l.sum():.3f}')
~~~

现在查看一下学习到的卷积核的权重张量。

~~~
conv2d.weight.data.reshape((1, 2))

# tensor([[ 0.9475, -1.0273]])
~~~

与初始权重K非常接近。

###### 2.5 特征映射和感受野

输出的卷积层有时被称为**特征映射（feature map）**，因为它可以被视为⼀个输⼊映射到下⼀层的空间维度的转换器。

在卷积神经⽹络中，对于某⼀层的任意元素x，其**感受野（receptive field）**是指在前向传播期间可能影响x计算的所有元素（来⾃所有先前层），换言之，它描述了 “当前层的一个特征是由输入图像中的哪些区域计算得到的”。

##### 3 填充和步幅

###### 3.1 填充

如上所述，在应⽤多层卷积时，我们常常丢失边缘像素。由于我们通常使⽤⼩卷积核，因此对于任何单个卷积，我们可能只会丢失⼏个像素。但随着我们应⽤许多连续卷积层，累积丢失的像素数就多了。

解决这个问题的简单⽅法即为**填充（padding）**：在输⼊图像的边界填充元素（通常填充元素是0）。

例如，我们将$3 \times 3$输⼊填充到$5 \times 5$，那么它的输出就增加为$4 \times 4$，而不再是$2 \times 2$。

![](/images/CNN/6.png)

通常，如果我们添加$p_h$⾏填充（⼤约⼀半在顶部，⼀半在底部）和$p_w$列填充（左侧⼤约⼀半，右侧⼀半），则输出形状将为:
$$(n_h − k_h + p_h + 1) \times (n_w − k_w + p_w + 1)$$

在许多情况下，我们需要设置$p_h = k_h − 1$和$p_w = k_w − 1$，使输⼊和输出具有相同的⾼度和宽度。这样可以在构建⽹络时更容易地预测每个图层的输出形状。假设$k_h$是奇数，我们将在⾼度的两侧填充$\frac{p_h}{2}$⾏。如果$k_h$是偶数，则⼀种可能性是在输⼊顶部填充$⌈\frac{p_h}{2}⌉$⾏，在底部填充$⌊\frac{p_h}{2}⌋$⾏。同理，我们填充宽度的两侧。

卷积神经⽹络中卷积核的⾼度和宽度通常为奇数，例如1、3、5或7。选择奇数的好处是，保持空间维度的同时我们可以在顶部和底部填充相同数量的⾏，在左侧和右侧填充相同数量的列。

###### 3.2 步幅

我们将每次滑动元素的数量称为**步幅（stride）**。在计算互相关时，卷积窗⼝从输⼊张量的左上⻆开始，向右、向下滑动。在前⾯的例⼦中，我们默认每次滑动⼀个元素。但是，有时候为了⾼效计算或是缩减采样次数，卷积窗⼝可以跳过中间位置，每次滑动多个元素。
如图是垂直步幅为3，⽔平步幅为2的⼆维互相关运算。

![](/images/CNN/7.png)

可以看到，为了计算输出中第⼀列的第⼆个元素和第⼀⾏的第⼆个元素，卷积窗⼝分别向下滑动三⾏和向右滑动两列。但是，当卷积窗⼝继续向右滑动两列时，没有输出，因为输⼊元素⽆法填充窗⼝（除⾮我们添加另⼀列填充）。

通常，当垂直步幅为$s_h$、⽔平步幅为$s_w$时，输出形状为
$$⌊(n_h − k_h + p_h + s_h)/s_h⌋ × ⌊(n_w − k_w + p_w + s_w)/sw⌋$$

###### 3.3 代码实现填充和修改步幅

~~~
# 批量⼤⼩、通道、卷积核尺寸（⾼度、宽度）、填充、步幅
nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)
~~~

为了简洁起⻅，当输⼊⾼度和宽度两侧的填充数量分别为$p_h$和$p_w$时，我们称之为填充$(p_h, p_w)$。当$p_h = p_w =p$时，填充是$p$。

同理，当⾼度和宽度上的步幅分别为$s_h$和$s_w$时，我们称之为步幅$(s_h, s_w)$。当时的步幅为$s_h = s_w = s$时，步幅为$s$。默认情况下，填充为0，步幅为1。

在实践中，我们很少使⽤不⼀致的步幅或填充，也就是说，我们通常有$p_h = p_w$和$s_h = s_w$。

所以有

$$ \text{输出尺寸} = \frac{\text{输入尺寸}+2 \times padding - kernel_{size}}{stride}+1$$

##### 4.多输入多输出通道

###### 4.1 多输入通道

当输⼊包含多个通道时，需要构造⼀个与输⼊数据具有相同输⼊通道数的卷积核，以便与输⼊数据进⾏互相关运算。假设输⼊的通道数为$c_i$，那么卷积核的输⼊通道数也需要为$c_i$。如果卷积核的窗⼝形状是$k_h ×k_w$，那么当$c_i = 1$时，我们可以把卷积核看作形状为$k_h × k_w$的⼆维张量。
然⽽，当$c_i > 1$时，我们卷积核的每个输⼊通道将包含形状为$k_h × k_w$的张量。将这些张量$c_i$连结在⼀起可以得到形状为$c_i × k_h × k_w$的卷积核。由于输⼊和卷积核都有$c_i$个通道，我们可以对每个通道输⼊的⼆维张量和卷积核的⼆维张量进⾏互相关运算，再对通道求和（将$c_i$的结果相加）得到⼆维张量。这是多通道输⼊和多输⼊通道卷积核之间进⾏⼆维互相关运算的结果。
下图演⽰了⼀个具有两个输⼊通道的⼆维互相关运算的⽰例。

![](/images/CNN/8.png)

###### 4.2 多输出通道

随着神经⽹络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更⼤的通道深度。直观地说，我们可以将每个通道看作是提取不同图像特征。⽽现实可能更为复杂⼀些，因为每个通道不是独⽴学习的，⽽是为了共同使⽤⽽优化的。因此，多输出通道并不仅是学习多个单通道的检测器。

⽤$c_i$和$c_o$分别表⽰输⼊和输出通道的数⽬，并让$k_h$和$k_w$为卷积核的⾼度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建⼀个形状为$c_i × k_h × k_w$的卷积核张量，这样卷积核的形状是$c_o × c_i × k_h × k_w$。在互相关运算中，每个输出通道先获取所有输⼊通道，再以对应该输出通道的卷积核计算出结果。

##### 5.汇聚层

- 降低数据维度：减少计算量和参数数量，提高模型训练效率，同时缓解过拟合问题。比如，在图像识别任务中，一张较大尺寸的图像经过多层卷积后特征图尺寸可能仍然较大，通过池化操作可以显著减小特征图的宽和高。

- 提升特征的平移不变性：让模型在识别特征时，对物体的位置变化更具鲁棒性。比如，无论物体在图像中的位置稍微向左或向右移动，经过池化层处理后，提取到的关键特征依然能够保持相对稳定。

汇聚层（Pooling Layer）有时也称池化层。

###### 5.1 最⼤汇聚层和平均汇聚层

与卷积层类似，汇聚层运算符由⼀个固定形状的窗⼝组成，该窗⼝根据其步幅⼤⼩在输⼊的所有区域上滑动，为固定形状窗⼝（有时称为汇聚窗⼝）遍历的每个位置计算⼀个输出。

然⽽，不同于卷积层中的输⼊与卷积核之间的互相关计算，汇聚层不包含参数。相反，池运算是确定性的，我们通常计算汇聚窗⼝中所有元素的最⼤值或平均值。这些操作分别称为**最⼤汇聚层（maximum pooling）**和**平均汇聚层（average pooling）**。

在这两种情况下，与互相关运算符⼀样，汇聚窗⼝从输⼊张量的左上⻆开始，从左往右、从上往下的在输⼊张量内滑动。在汇聚窗⼝到达的每个位置，它计算该窗⼝中输⼊⼦张量的最⼤值或平均值。计算最⼤值或平均值是取决于使⽤了最⼤汇聚层还是平均汇聚层。

下图是一个最大汇聚层例子。

![](/images/CNN/9.png)

$$max(0, 1, 3, 4) = 4$$

$$max(1, 2, 4, 5) = 5$$

$$max(3, 4, 6, 7) = 7$$

$$max(4, 5, 7, 8) = 8$$

汇聚窗⼝形状为$p × q$的汇聚层称为p × q汇聚层，汇聚操作称为$p × q$汇聚。

现在自定义一个函数实现汇聚层操作。

~~~
# 自定义汇聚层
import torch
from torch import nn

def pool2d(X, pool_size, mode='max'):
    # 获取汇聚层尺寸
    p_h, p_w = pool_size
    # 设置输出层尺寸
    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i, j] = X[i: i + p_h, j: j + p_w].max()
            elif mode == 'avg':
                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()
    return Y

X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
print(pool2d(X, (2, 2), 'max'))
print(pool2d(X, (2, 2), 'avg'))
~~~

###### 5.2 填充和步幅

与卷积层⼀样，汇聚层也可以改变输出形状。和以前⼀样，我们可以通过填充和步幅以获得所需的输出形状。

~~~
# 最大汇聚层，窗口尺寸，填充，步幅
nn.MaxPool2d(kernel_size=3, padding=1, stride=2)

# 最大汇聚层，窗口尺寸，填充（0表示不填充），步幅，
nn.MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=(0, 1))

# 平均汇聚层，窗口尺寸，无填充，步幅
nn.AvgPool2d(kernel_size=2, stride=2) 
~~~

###### 5.3 多个通道

在处理多通道输⼊数据时，汇聚层在每个输⼊通道上单独运算，⽽不是像卷积层⼀样在通道上对输⼊进⾏汇总。这意味着汇聚层的输出通道数与输⼊通道数相同。

##### 6.卷积神经网络LeNet

最后一节，介绍一下最早发布的卷积神经⽹络LeNet。

总体来看，LeNet（LeNet-5）由两个部分组成：

- 卷积编码器：由两个卷积层组成；

- 全连接层密集块：由三个全连接层组成。

![](/images/CNN/10.png)

上图是LeNet处理手写数字图像分类的网络架构图。每个卷积块中的基本单元是⼀个卷积层、⼀个sigmoid激活函数和平均汇聚层。每个卷积层使⽤5 × 5卷积核和⼀个sigmoid激活函数。

第⼀卷积层有6个输出通道，⽽第⼆个卷积层有16个输出通道。每个2 × 2汇聚操作通过空间下采样将维数减少4倍。卷积的输出形状由批量⼤⼩、通道数、⾼度、宽度决定。

为了将卷积块的输出传递给稠密块，我们必须在⼩批量中展平每个样本。换⾔之，我们将这个四维输⼊转换成全连接层所期望的⼆维输⼊，第⼀个维度是批量大小，第⼆个维度是每个样本的特征表示，是一个一维向量。

LeNet的稠密块有三个全连接层，分别有120、84和10个输出。因为我们在执⾏分类任务，所以输出层的10维对应于最后输出结果的数量。

~~~
import torch
from torch import nn      
    
net_LeNet = nn.Sequential(
    # 输入通道、输出通道、卷积核、填充、步幅为默认1
    nn.Conv2d(1, 6, kernel_size=5, padding=2), # 卷积层
    nn.Sigmoid(), # 激活层
    # 汇聚窗口、无填充、步幅
    nn.AvgPool2d(kernel_size=2, stride=2), # 平均汇聚层（池化层）
    # 输入通道、输出通道、卷积核、无填充、步幅为默认1
    nn.Conv2d(6, 16, kernel_size=5),
    nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    # 特征向量展平为一维向量
    nn.Flatten(), # 展平层
    # 输入通道（上一层特征输出通道*尺寸）、输出通道
    nn.Linear(16 * 5 * 5, 120), # 全连接层
    nn.Sigmoid(),
    nn.Linear(120, 84),
    nn.Sigmoid(),
    nn.Linear(84, 10))

x_LeNet = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)

for layer in net_LeNet:
    x_LeNet = layer(x_LeNet)
    print(layer.__class__.__name__,'output shape: \t',x_LeNet.shape)
~~~

![](/images/CNN/11.png)

输出尺寸的计算公式，在前文已经提过，这里不再赘述，下一节介绍一些常见的网络架构。
