---
title: 机器学习（21）密度聚类——Density-Based Spatial Clustering of Appliactions with Noise，DBSCAN
tags: ML Clustering
typora-root-url: ./..
---

思想：基于一组邻域参数半径（Eps）和最小数量（MinPts）来刻画样本分布的紧密程度。

<!--more-->

论文：A density-based algorithm for discovering clusters in large spatial databases with noise

##### 1.概念

给定数据集$D=\lbrace \mathbf{x}_1,\mathbf{x}_2,\cdots,\mathbf{x}_m \rbrace$，定义如下概念

- $\epsilon$-邻域

对$ \mathbf{x}_j \in D $，其$\epsilon$-邻域包含样本集D在与$ \mathbf{x}_j $的距离不大于$ \epsilon $的样本，即$ ( \mathbf{x}_j) = \lbrace \mathbf{x}_i \in D \mid dist( \mathbf{x}_i, \mathbf{x}_j ) \leq \epsilon \rbrace $；

人话：以样本$\mathbf{x}_j$为圆心，$\epsilon$为半径画圆，圆内和圆上的其他样本都是样本$\mathbf{x}_j$的$\epsilon$-邻域。

- 核心对象（core object）

若$ \mathbf{x}_j $的$ \epsilon $-邻域至少包含MinPts个样本，即$  \geq MinPts $，则$\mathbf{x}_j$是一个核心对象。MinPts是一个超参数；

人话：以样本$ \mathbf{x}_j $为圆心，$\epsilon$为半径的圆，如果圆里面样本数量大于等于某个数，那样本$\mathbf{x}_j$就是核心对象。

- 密度直达（directly density-reachable）

若$\mathbf{x}_j$位于$\mathbf{x}_i$的$\epsilon$-邻域中，且$\mathbf{x}_i$是核心对象，则称$\mathbf{x}_j$由$\mathbf{x}_i$密度直达；

人话：核心对象B在核心对象A的圆里面，那么B由A直接到达。

- 密度可达（density-reachable）

对$ \mathbf{x}_j $与$ \mathbf{x}_i $，若存在样本序列$ z_1, z_2 , \cdots , z_n $，其中$ z_1 = x_i , z_n = x_j $且$ z_{i+1} $由$ z_i $密度直达，则称$ \mathbf{x}_j $由$ \mathbf{x}_i $密度可达；

人话：两个核心对象不能直接到，如果能通过其他的核心对象间接到达，就是可达的；

- 密度相连（density-connected）

对$\mathbf{x}_j$与$\mathbf{x}_i$，若存在$\mathbf{x}_k$使得$\mathbf{x}_j$与$\mathbf{x}_i$均由$\mathbf{x}_k$密度可达，则称$\mathbf{x}_j$与$\mathbf{x}_i$密度相连。

人话：两个核心对象都可以由另一个核心对象到达，这两个核心对象就是相连的。

![](/assets/images/DBSCAN/one.png)

上图展示了这几个概念，当MinPts=3时，虚线为$\epsilon$-邻域，$x_1,x_2,x_3,x_4$是核心对象，$x_2$由$x_1$密度直达，$x_3$由$x_1$密度可达，$x_3$与$x_4$密度相连。

##### 2.簇划分

基于上述这些概念，DBSCAN将“簇”定义为：由密度可达关系导出的密度相连样本集合。给定邻域参数$(\epsilon,MinPts)$，簇$C \subseteq  D$要满足两个条件：

- 最大性：若$\mathbf{x}_i\in C$且$\mathbf{x}_j$由$\mathbf{x}_i$密度可达，则$\mathbf{x}_j\in C$，也就是密度可达的两个样本属于同一簇。

- 连接性：若$\mathbf{x}_i\in C$，$\mathbf{x}_j\in C$，则$\mathbf{x}_i$与$\mathbf{x}_j$密度相连，也就是同一个簇内的两个样本一定密度相连。

若$\mathbf{x}$是核心对象，由$\mathbf{x}$密度可达的所有样本组成的集合记为$X=\lbrace \mathbf{x}^{'}\in D \mid \mathbf{x}^{'} 由 \mathbf{x} 密度可达\rbrace$就是满足最大性和连接性的簇。

##### 3.算法步骤

（1）设定初始值$(\epsilon,MinPts)$，找出所有的核心对象；

（2）以任意一个核心对象出发，找到它密度可达的样本生成聚类簇，重复这一过程直到所有点都被访问。

##### 4.其他问题

（1）一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象的周围，在DBSCAN中，一般将这些样本点标记为噪音点。

（2）距离的度量问题，即如何计算某样本和核心对象样本的距离。在DBSCAN中，一般采用最近邻思想，采用某一种距离度量来衡量样本距离，比如欧式距离。这和KNN分类算法的最近邻思想完全相同。对应少量的样本，寻找最近邻可以直接去计算所有样本的距离，如果样本量较大，则一般采用KD树或者球树来快速的搜索最近邻。

（3）某些样本可能到两个核心对象的距离都小于ϵ，但是这两个核心对象由于不是密度直达，又不属于同一个聚类簇，此时DBSCAN采用先来后到，先进行聚类的类别簇会标记这个样本为它的类别。也就是说DBSCAN的算法不是完全稳定的算法。

##### 5.优缺点

优点

- 可以对任意形状的稠密数据集进行聚类。

- 可以在聚类的同时发现异常点，对数据集中的异常点不敏感。

缺点

- 如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差。

- 如果样本集较大时，聚类收敛时间较长。

- 调参相对于稍复杂，主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响。

~~~
~~~



~~~
# sklearn实现
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN

# 西瓜数据集4.0
data = np.array([
    [1, 0.697, 0.460, 1],
    [2, 0.774, 0.376, 1],
    [3, 0.634, 0.264, 1],
    [4, 0.608, 0.318, 1],
    [5, 0.556, 0.215, 1],
    [6, 0.403, 0.237, 0],
    [7, 0.481, 0.149, 0],
    [8, 0.437, 0.211, 0],
    [9, 0.666, 0.091, 0],
    [10, 0.243, 0.267, 0],
    [11, 0.245, 0.057, 0],
    [12, 0.343, 0.099, 0],
    [13, 0.639, 0.161, 1],
    [14, 0.657, 0.198, 1],
    [15, 0.360, 0.370, 0],
    [16, 0.593, 0.042, 0],
    [17, 0.719, 0.103, 1],
    [18, 0.359, 0.188, 0],
    [19, 0.339, 0.241, 0],
    [20, 0.282, 0.257, 0],
    [21, 0.748, 0.232, 1],
    [22, 0.714, 0.346, 1],
    [23, 0.483, 0.312, 0],
    [24, 0.478, 0.437, 0],
    [25, 0.525, 0.369, 1],
    [26, 0.751, 0.489, 1],
    [27, 0.532, 0.472, 1],
    [28, 0.473, 0.376, 0],
    [29, 0.725, 0.445, 1],
    [30, 0.446, 0.459, 0]
])

# 提取密度和含糖率作为特征
X = data[:, 1:3]

# 使用DBSCAN进行聚类
# eps: 邻域半径
# min_samples: 最小样本数
dbscan = DBSCAN(eps=0.11, min_samples=5)
labels = dbscan.fit_predict(X)

# 可视化结果
plt.figure(figsize=(8, 6))
unique_labels = set(labels)  # 获取所有不同的标签
colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]

for k, col in zip(unique_labels, colors):
    if k == -1:
        col = [0, 0, 0, 1]  # 黑色表示噪声点

    class_member_mask = labels == k  # 获取当前类别的掩码
    xy = X[class_member_mask]  # 获取当前类别的数据点
    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col), markeredgecolor='k', markersize=14)

plt.title('DBSCAN Clustering')
plt.xlabel('Density')
plt.ylabel('Sugar Content')
plt.show()
~~~

